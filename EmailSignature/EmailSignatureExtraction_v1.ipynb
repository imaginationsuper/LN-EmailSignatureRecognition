{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use talon to extract the email signatures as training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Mr. Ray,\n",
      "\n",
      "I regret to inform you that due to very heavy workload we cannot attend\n",
      "the Power Systems Engineering Research Center's\n",
      "upcoming Industrial Advisory Board meeting in Oak Brook.   \n",
      "\n",
      "Our  work load does not leave us much time to get involved\n",
      "with PSERC at this moment. We would very much like to stay\n",
      "in touch and plan to reconsider our decision in the second half of this year.\n",
      "\n",
      "Vince Kaminski\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"Dennis Ray\" <djray@engr.wisc.edu> on 03/27/2001 04:46:44 PM\n",
      "To:\t\"Vince Kaminski\" <Vince.J.Kaminski@enron.com>\n",
      "cc:\t \n",
      "Subject:\tPSERC Industrial Advisory Board Meeting Invitation\n",
      "\n",
      "\n",
      "Mr. Kaminski,\n",
      "\n",
      "Greetings. Bob Thomas, Shmuel Oren and I invite you to attend the Power\n",
      "Systems Engineering Research Center's upcoming Industrial Advisory Board\n",
      "meeting in Oak Brook, IL. It will be held on May 31 - June 1.\n",
      "\n",
      "As you know from Lance and Alex, this is an opportunity to meet university\n",
      "researchers and industrial members of PSERC. The meeting also has\n",
      "presentations on PSERC activities and research projects, PSERC business\n",
      "discussions, current topic discussions, and a tutorial. Our current topics\n",
      "discussion will be on ISO/RTO issues, and will involve executives from\n",
      "several ISOs in dialog with university researchers.\n",
      "\n",
      "Please let me know if you have any questions. We hope to see you there so\n",
      "that we can talk about any questions you might have about PSERC.\n",
      "\n",
      "\n",
      "Dennis Ray, Ph.D.\n",
      "Executive Director\n",
      "Power Systems Engineering Research Center\n",
      "608-265-3808\n",
      "\n",
      " - Directions.doc \n",
      " - IAB_Meeting_May2001.doc \n",
      " - IAB_Registration_Form.doc \n",
      " - PSERC Members.doc\n"
     ]
    }
   ],
   "source": [
    "import talon\n",
    "from talon import quotations\n",
    "talon.init()\n",
    "text = \"\"\"\n",
    "Dear Mr. Ray,\n",
    "\n",
    "I regret to inform you that due to very heavy workload we cannot attend\n",
    "the Power Systems Engineering Research Center's\n",
    "upcoming Industrial Advisory Board meeting in Oak Brook.   \n",
    "\n",
    "Our  work load does not leave us much time to get involved\n",
    "with PSERC at this moment. We would very much like to stay\n",
    "in touch and plan to reconsider our decision in the second half of this year.\n",
    "\n",
    "Vince Kaminski\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"Dennis Ray\" <djray@engr.wisc.edu> on 03/27/2001 04:46:44 PM\n",
    "To:\t\"Vince Kaminski\" <Vince.J.Kaminski@enron.com>\n",
    "cc:\t \n",
    "Subject:\tPSERC Industrial Advisory Board Meeting Invitation\n",
    "\n",
    "\n",
    "Mr. Kaminski,\n",
    "\n",
    "Greetings. Bob Thomas, Shmuel Oren and I invite you to attend the Power\n",
    "Systems Engineering Research Center's upcoming Industrial Advisory Board\n",
    "meeting in Oak Brook, IL. It will be held on May 31 - June 1.\n",
    "\n",
    "As you know from Lance and Alex, this is an opportunity to meet university\n",
    "researchers and industrial members of PSERC. The meeting also has\n",
    "presentations on PSERC activities and research projects, PSERC business\n",
    "discussions, current topic discussions, and a tutorial. Our current topics\n",
    "discussion will be on ISO/RTO issues, and will involve executives from\n",
    "several ISOs in dialog with university researchers.\n",
    "\n",
    "Please let me know if you have any questions. We hope to see you there so\n",
    "that we can talk about any questions you might have about PSERC.\n",
    "\n",
    "\n",
    "Dennis Ray, Ph.D.\n",
    "Executive Director\n",
    "Power Systems Engineering Research Center\n",
    "608-265-3808\n",
    "\n",
    " - Directions.doc \n",
    " - IAB_Meeting_May2001.doc \n",
    " - IAB_Registration_Form.doc \n",
    " - PSERC Members.doc \n",
    "\"\"\"\n",
    "\n",
    "reply = quotations.extract_from_plain(text)\n",
    "from talon import signature\n",
    "from talon.signature.bruteforce import extract_signature\n",
    "text, signature = signature.extract(reply, sender='vince.kaminski@enron.com')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talon results are not always good and can only apply certain well-formated cases. So pick the email signature corpus manually. ~~First, use the Python email package to extract the main body (including the signature). Then apply the talon to strip off the signature part.~~ First, manually extract the ground signatures from the top 100 emails of 'kaminski-v/conferences/', and save in one file (_EnronSignatures.txt_) separated by an empty line. Also the emails from Jeb Bush folder within file '12+December+2003+Public+2.txt', and save into one file '_JebBushSignatures.txt_'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the signature corpus to train the word vector to recognize the email signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sincerely, thaleia zariphopoulou chair of the scientific committee v.n.neuhaus professor dpts of mathematics and msis the university of texas at austin', 'thank you, clare fitzgerald director, training courses marcus evans 312-540-3000x6785', 'joanna vidal events coordinator risk waters group t: (212) 925 1864 ext. 197 f: (212) 925 7585 jvidal@riskwaters.com www.riskwaters.com', 'duane seppi carnegie mellon university graduate school of industrial administrations pittsburgh, pa 15213-3890 t: 001 412-268-2298 f: 001 412-269-8896', 'helyette geman universite de paris dauphine finance department au de ka grand ecole corgy pontois, paris france 95021 t: 00 33 60-807-4200', 'vincent kaminski enron credit 1400 smith street room eb1962 houston, tx 77002-7361 t: 001 713-853-3848 f: 001 713-646-2503', 'peter nance teknecon, inc. 1515 s. capital of texas highway suite 101 austin, tx 78746 t: 001 512-732-7084 f: 001 512-732-7099', 'chris harris innogy holdings place windmill hill business park whitehill way swindon, wiltshire uk, 5n5 6pb t: 44 793 387-7777 f: 44 793 389-7811', 'spyros maragos dynergy, inc. 1000 louisiana street suite 5800 houston, tx 77002 t: 011 713-507-6589 f: 001 713-767-5958', 'ehud ronn university of texas at austin department of finance mccombs school of business austin, tx 78712-1179 t: 001 512-471-5853 f: 001 512-471-5073']\n"
     ]
    }
   ],
   "source": [
    "# read in the signature text file\n",
    "fname = \"EnronSignatures.txt\"\n",
    "fsig = open(fname, 'r')\n",
    "sigList = []\n",
    "sigText = []\n",
    "for line in fsig.readlines():\n",
    "    #print len(line)\n",
    "    if len(line) <= 3:\n",
    "        sigList.append(' '.join(sigText)) # combine all the texts of each signature\n",
    "        sigText = []\n",
    "    else:\n",
    "        sigText.append(' '.join(line.lower().split()))\n",
    "fsig.close()\n",
    "\n",
    "print(sigList[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Use word2vec to train directly\n",
    "from gensim import corpora, models, similarities\n",
    "sigTexts = []\n",
    "for term in sigList:\n",
    "    sigTexts.append([word for word in term.split()])\n",
    "model = models.word2vec.Word2Vec(sigTexts, min_count=1)\n",
    "print(model.doesnt_match('thank you but'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, extract the body(excluding email signatures) text from Enron dataset 'kaminski-v/conferences/', and use as negative training set. Try to make use of both talon and Python email packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import os\n",
    "import re\n",
    "import talon\n",
    "from talon import quotations\n",
    "from talon import signature\n",
    "from talon.signature.bruteforce import extract_signature\n",
    "import email\n",
    "from email.parser import Parser\n",
    "talon.init()\n",
    "dirName = \"conferences\"\n",
    "#filelist = [fn for fn in os.listdir(dirName) if fn != \".\"]\n",
    "#print filelist\n",
    "os.chdir(dirName)\n",
    "fcontent = open(\"content.txt\",'w')\n",
    "for fe in range(1,101):\n",
    "    fname = str(fe)+'.'\n",
    "    if not os.path.exists(fname):\n",
    "        continue\n",
    "    fmail = open(fname, 'r')\n",
    "    mailText = ''.join(fmail.readlines())\n",
    "    content = email.message_from_string(mailText)\n",
    "    if content is None:\n",
    "        continue\n",
    "    body = []\n",
    "    if content.is_multipart():\n",
    "        for payload in content.get_payload():\n",
    "            body.append(payload.get_payload())\n",
    "    else:\n",
    "        body.append(content.get_payload())\n",
    "    if body is None: # discard mail without body\n",
    "        fmail.close()\n",
    "        continue\n",
    "    #body = ''.join(body)\n",
    "    bodyText = []\n",
    "    sigSymbols = ['-- forwarded by', 'sincerely', 'kind regards', 'thank you', 'thanks']\n",
    "    for entry in body:\n",
    "        findEnd = False\n",
    "        for sym in sigSymbols:\n",
    "            if sym in entry.lower():\n",
    "                findEnd = True\n",
    "        if findEnd:\n",
    "            break\n",
    "        bodyText.append(entry)\n",
    "    reply = quotations.extract_from_plain(''.join(bodyText))\n",
    "    texts, signature = extract_signature(reply)\n",
    "    fcontent.write(texts)\n",
    "    fcontent.write('\\n')\n",
    "    fmail.close()\n",
    "fcontent.close()\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now train the model using signature text as the positive dataset and body content text as the negative dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sincerely,', 'thaleia', 'zariphopoulou', 'chair', 'of', 'the', 'scientific', 'committee', 'v.n.neuhaus', 'professor', 'dpts', 'of', 'mathematics', 'and', 'msis', 'the', 'university', 'of', 'texas', 'at', 'austin'], ['thank', 'you,', 'clare', 'fitzgerald', 'director,', 'training', 'courses', 'marcus', 'evans', '312-540-3000x6785'], ['joanna', 'vidal', 'events', 'coordinator', 'risk', 'waters', 'group', 't:', '(212)', '925', '1864', 'ext.', '197', 'f:', '(212)', '925', '7585', 'jvidal@riskwaters.com', 'www.riskwaters.com'], ['duane', 'seppi', 'carnegie', 'mellon', 'university', 'graduate', 'school', 'of', 'industrial', 'administrations', 'pittsburgh,', 'pa', '15213-3890', 't:', '001', '412-268-2298', 'f:', '001', '412-269-8896'], ['helyette', 'geman', 'universite', 'de', 'paris', 'dauphine', 'finance', 'department', 'au', 'de', 'ka', 'grand', 'ecole', 'corgy', 'pontois,', 'paris', 'france', '95021', 't:', '00', '33', '60-807-4200'], ['vincent', 'kaminski', 'enron', 'credit', '1400', 'smith', 'street', 'room', 'eb1962', 'houston,', 'tx', '77002-7361', 't:', '001', '713-853-3848', 'f:', '001', '713-646-2503'], ['peter', 'nance', 'teknecon,', 'inc.', '1515', 's.', 'capital', 'of', 'texas', 'highway', 'suite', '101', 'austin,', 'tx', '78746', 't:', '001', '512-732-7084', 'f:', '001', '512-732-7099'], ['chris', 'harris', 'innogy', 'holdings', 'place', 'windmill', 'hill', 'business', 'park', 'whitehill', 'way', 'swindon,', 'wiltshire', 'uk,', '5n5', '6pb', 't:', '44', '793', '387-7777', 'f:', '44', '793', '389-7811'], ['spyros', 'maragos', 'dynergy,', 'inc.', '1000', 'louisiana', 'street', 'suite', '5800', 'houston,', 'tx', '77002', 't:', '011', '713-507-6589', 'f:', '001', '713-767-5958'], ['ehud', 'ronn', 'university', 'of', 'texas', 'at', 'austin', 'department', 'of', 'finance', 'mccombs', 'school', 'of', 'business', 'austin,', 'tx', '78712-1179', 't:', '001', '512-471-5853', 'f:', '001', '512-471-5073']]\n",
      "[['please', 'register', 'wincenty', 'j.', '(vince)', 'kaminski,', 'managing', 'director,', 'research'], ['enron', 'wholesale', 'services,', 'to', 'the', 'subject', 'conference', 'to', 'be', 'held', 'in', 'houston'], ['on', 'june', '22,', '2001.'], ['if', 'you', 'need', 'more', 'information,', 'please', 'contact', 'me', 'at:'], ['dear', 'mr.', 'ray,'], ['i', 'regret', 'to', 'inform', 'you', 'that', 'due', 'to', 'very', 'heavy', 'workload', 'we', 'cannot', 'attend'], ['the', 'power', 'systems', 'engineering', 'research', \"center's\"], ['upcoming', 'industrial', 'advisory', 'board', 'meeting', 'in', 'oak', 'brook.'], ['our', 'work', 'load', 'does', 'not', 'leave', 'us', 'much', 'time', 'to', 'get', 'involved'], ['with', 'pserc', 'at', 'this', 'moment.', 'we', 'would', 'very', 'much', 'like', 'to', 'stay']]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "from gensim.models.doc2vec import LabeledSentence, Doc2Vec\n",
    "import collections\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.linear_model\n",
    "import nltk\n",
    "def load_data(path_to_data):\n",
    "    train_pos = []\n",
    "    train_neg = []\n",
    "    sigwords = []\n",
    "    with open(path_to_data+\"EnronSignatures.txt\",'r') as fes:\n",
    "        for line in fes:\n",
    "            if len(line) <= 3:\n",
    "                train_pos.append((' '.join(sigwords)).split()) # combine all the texts of each signature\n",
    "                sigwords = []\n",
    "            else:\n",
    "                sigwords.append(' '.join(line.lower().strip().split()))\n",
    "    with open(path_to_data+\"train_content.txt\",'r') as ftc:\n",
    "        for line in ftc:\n",
    "            words = [w.lower() for w in line.strip().split()]\n",
    "            if len(words) < 2:\n",
    "                continue\n",
    "            train_neg.append(words)\n",
    "    return train_pos, train_neg\n",
    "\n",
    "train_pos, train_neg = load_data('./')\n",
    "print train_pos[:10]\n",
    "print train_neg[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features for training process using gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 0\n",
      "Training iteration 1\n",
      "Training iteration 2\n",
      "Training iteration 3\n",
      "Training iteration 4\n"
     ]
    }
   ],
   "source": [
    "def feature_extraction(train_pos, train_neg):\n",
    "    labeled_train_pos = []\n",
    "    for index, words in enumerate(train_pos):\n",
    "        sentence = LabeledSentence(words, [\"TRAIN_POS_%s\"%index])\n",
    "        labeled_train_pos.append(sentence)\n",
    "    labeled_train_neg = []\n",
    "    for index, words in enumerate(train_neg):\n",
    "        sentence = LabeledSentence(words, [\"TRAIN_NEG_%s\"%index])\n",
    "        labeled_train_neg.append(sentence)\n",
    "    model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=4)\n",
    "    sentences = labeled_train_pos + labeled_train_neg\n",
    "    model.build_vocab(sentences)\n",
    "    for i in range(5):\n",
    "        print \"Training iteration %d\" %(i)\n",
    "        random.shuffle(sentences)\n",
    "        model.train(sentences)\n",
    "    train_pos_vec, train_neg_vec = [], []\n",
    "    for index in range(len(labeled_train_pos)):\n",
    "        doc_vec = model.docvecs[\"TRAIN_POS_%s\"%index]\n",
    "        train_pos_vec.append(doc_vec)\n",
    "    for index in range(len(labeled_train_neg)):\n",
    "        doc_vec = model.docvecs[\"TRAIN_NEG_%s\"%index]\n",
    "        train_neg_vec.append(doc_vec)\n",
    "    return train_pos_vec, train_neg_vec\n",
    "\n",
    "train_pos_vec, train_neg_vec = feature_extraction(train_pos, train_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the transformed vectors to build model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(train_pos_vec, train_neg_vec):\n",
    "    Y = [\"pos\"]*len(train_pos_vec) + [\"neg\"]*len(train_neg_vec)\n",
    "    X = train_pos_vec + train_neg_vec\n",
    "    lr_model = sklearn.linear_model.LogisticRegression()\n",
    "    lr_model.fit(X,Y)\n",
    "    return lr_model\n",
    "\n",
    "lr_model = build_model(train_pos_vec, train_neg_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model using the training (testing) data by presenting the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:\tpos\tneg\n",
      "actual:\n",
      "pos\t\t0\t45\n",
      "neg\t\t0\t338\n",
      "accuracy: 0.880208\n",
      "precision: 0.000000\n",
      "recall: 0.000000\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_pos_vec, test_neg_vec, print_confusion=False):\n",
    "    test_pos_predict = model.predict(test_pos_vec)\n",
    "    test_neg_predict = model.predict(test_neg_vec)\n",
    "    test_pos_Y = [\"pos\"]*len(test_pos_vec)\n",
    "    test_neg_Y = [\"neg\"]*len(test_neg_vec)\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(len(test_pos_predict)):\n",
    "        if test_pos_predict[i] == test_pos_Y[i]:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    for i in range(len(test_neg_predict)):\n",
    "        if test_neg_predict[i] == test_neg_Y[i]:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    accuracy = float(tp+tn) / float(tp+tn+fp+fn+1)\n",
    "    precision = float(tp) / float(tp+fp+1)\n",
    "    recall = float(tp) / float(tp+fn+1)\n",
    "    if print_confusion:\n",
    "        print \"predicted:\\tpos\\tneg\"\n",
    "        print \"actual:\"\n",
    "        print \"pos\\t\\t%d\\t%d\" % (tp, fn)\n",
    "        print \"neg\\t\\t%d\\t%d\" % (fp, tn)\n",
    "    print \"accuracy: %f\" % (accuracy)\n",
    "    print \"precision: %f\" % (precision)\n",
    "    print \"recall: %f\" % (recall)\n",
    "    \n",
    "evaluate_model(lr_model, train_pos_vec, train_neg_vec, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
